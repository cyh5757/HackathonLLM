import asyncio
from app.core.agent_tools import llm
from app.services.rag_agent import (
    query_snack_recommendation,
    agent_executor,
    decision_maker,
    llm_answer,
    vector_search,
    get_session_history,
)
from langchain.agents import tool, create_tool_calling_agent, AgentExecutor
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables.history import RunnableWithMessageHistory


# ğŸ”§ LangChain Tools ì •ì˜ (ë¹„ë™ê¸°)
@tool
async def sql_search(input: str) -> str:
    """SQL ê¸°ë°˜ ìŠ¤ë‚µ ì¶”ì²œ"""
    return await query_snack_recommendation(agent_executor, input, limit=5)


@tool
async def vector_search_A(input: str) -> str:
    """ë²¡í„° ê¸°ë°˜ ê²€ìƒ‰ (ìŠ¤ë‚µ/ì²¨ê°€ë¬¼ ì •ë³´)"""
    return await vector_search(input)


@tool
async def decision_maker_A(question: str, context: str) -> str:
    """
    ì—¬ëŸ¬ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ í•µì‹¬ ë¬¸ë§¥ ì¶”ì¶œ
    """
    state = {
        "question": question,
        "context": context,
        "organize_reference": "",
    }
    result_state = await decision_maker(state)
    return result_state["organize_reference"]


@tool
async def llm_answer_A(question: str, context: str) -> str:
    """
    ìµœì¢… ë‹µë³€ ìƒì„±
    """
    state = {
        "question": question,
        "context": context,
        "organize_reference": "",
    }
    result_state = await llm_answer(state)
    return result_state["answer"]


# ğŸ§  Agent Prompt ì„¤ì •
agent_prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            """You are a helpful assistant, and you use Korean.
        You have tools: sql_search, vector_search_A, decision_maker_A, llm_answer_A.
        Use search tools first, summarize with decision_maker_A, and finish with llm_answer_A.""",
        ),
        ("placeholder", "{chat_history}"),
        ("human", "{input}"),
        ("placeholder", "{agent_scratchpad}"),
    ]
)


# ğŸ§  Agent ìƒì„± í•¨ìˆ˜ (ë¹„ë™ê¸°)
# ì „ì²´ ì—ì´ì „íŠ¸ ì‹¤í–‰ì„ ë‹´ë‹¹í•˜ëŠ” ë¹„ë™ê¸° í•¨ìˆ˜
async def run_agent_full(input_text: str):
    # LangChainì˜ create_tool_calling_agentë¥¼ ì‚¬ìš©í•˜ì—¬ Tool ê¸°ë°˜ LLM Agent ìƒì„±
    # ì´ AgentëŠ” ë‚´ë¶€ì ìœ¼ë¡œ ì‚¬ìš©ìê°€ ì •ì˜í•œ Tool ë“¤ì„ í˜¸ì¶œí•  ìˆ˜ ìˆìŒ
    agent = create_tool_calling_agent(
        llm,
        tools=[
            sql_search,
            vector_search_A,
            decision_maker_A,
            llm_answer_A,
        ],  # ì •ì˜í•œ Tool ëª©ë¡
        prompt=agent_prompt,  # ì—ì´ì „íŠ¸ê°€ ë”°ë¥¼ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
    )

    # AgentExecutorëŠ” ìœ„ì—ì„œ ë§Œë“  agentë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ì‹¤í–‰ê¸°
    executor = AgentExecutor(
        agent=agent,
        tools=[
            sql_search,
            vector_search_A,
            decision_maker_A,
            llm_answer_A,
        ],  # toolë“¤ì„ agentì—ê²Œ ë‹¤ì‹œ ì—°ê²°
        verbose=True,  # ì‹¤í–‰ ê³¼ì • ë¡œê·¸ ì¶œë ¥
        max_iterations=10,  # ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ (tool ì‚¬ìš© ë°˜ë³µ)
        handle_parsing_errors=True,  # LLM ì¶œë ¥ì´ íŒŒì‹± ì•ˆ ë˜ë©´ ìë™ ë³µêµ¬ ì‹œë„
        return_intermediate_steps=False,  # ì¤‘ê°„ tool ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ì§€ ì•ŠìŒ
    )

    # ëŒ€í™” ê¸°ë¡ì„ ìœ ì§€í•˜ê¸° ìœ„í•œ ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ ë˜í¼
    agent_with_history = RunnableWithMessageHistory(
        executor,  # ìœ„ì—ì„œ ì •ì˜í•œ AgentExecutor
        get_session_history,  # ì„¸ì…˜ IDì— ë”°ë¼ ëŒ€í™” ì´ë ¥ì„ ì €ì¥í•˜ëŠ” í•¨ìˆ˜
        input_messages_key="input",  # ì‚¬ìš©ì ì…ë ¥ í‚¤
        history_messages_key="chat_history",  # ê¸°ë¡ë  íˆìŠ¤í† ë¦¬ í‚¤
    )

    # ì—ì´ì „íŠ¸ ì‹¤í–‰ (ì…ë ¥ê°’ê³¼ ì„¸ì…˜ID í¬í•¨)
    result = await agent_with_history.ainvoke(
        {"input": input_text},
        config={"configurable": {"session_id": "rag123"}},  # ì„¸ì…˜ IDë¥¼ ë„˜ê¹€
    )

    # ìµœì¢… ì‘ë‹µ ë°˜í™˜
    return result


# ğŸš€ ì‹¤í–‰
if __name__ == "__main__":

    async def main():
        user_input = "ì–´ë¦°ì´ì—ê²Œ ì¢‹ì€ ê³¼ìë¥¼ ì¶”ì²œí•´ì¤˜"
        result = await run_agent_full(user_input)
        print("ìµœì¢… ê²°ê³¼:\n", result["output"])

    # agent tools
    # prompt chain : prompt split
    # routings : agentic loop
    # parelllization : master + worker
    # context window lenght : 5
    # agentic loop :
    asyncio.run(main())
